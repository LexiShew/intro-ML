{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process\r\n",
    "* create a small data set (only 12 elements) to look at text processing and see how BoW vectorization works\r\n",
    "* create vectors for the data\r\n",
    "    * default\r\n",
    "    * exclude common words\r\n",
    "    * exclude rare words\r\n",
    "    * count # of times word is used in single review? or just present at all\r\n",
    "    * look at word pairs? word triples? expensive to generate, could produce better results\r\n",
    "* train a simple logistic regression on the data\r\n",
    "    * look at all different vectors, see which set is best\r\n",
    "* tweak logistic hyperparams\r\n",
    "* train MLP\r\n",
    "* train decision tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# imports\r\n",
    "\r\n",
    "import re\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn import linear_model\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "from sklearn.metrics import log_loss\r\n",
    "from sklearn.preprocessing import minmax_scale\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.model_selection import RandomizedSearchCV\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data processing\r\n",
    "* Removing whitespace and punctuation\r\n",
    "* Converting to all lowercase\r\n",
    "* Generating vectors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Default BoW"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # count vectorizer\r\n",
    "# raw_reviews = pd.read_csv('data/data_reviews/x_train.csv')['text'].values.tolist()\r\n",
    "# reviews = list()\r\n",
    "\r\n",
    "# pattern = re.compile('[^a-z ]')\r\n",
    "# for review in raw_reviews:\r\n",
    "#     review = review.lower()\r\n",
    "#     review = pattern.sub('', review)\r\n",
    "#     reviews.append(review)\r\n",
    "\r\n",
    "# vectorizer = CountVectorizer()\r\n",
    "# X = vectorizer.fit_transform(reviews)\r\n",
    "# y = pd.read_csv('data/data_reviews/y_train.csv').to_numpy().ravel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # TF-IDF vectorizor\r\n",
    "# raw_reviews = pd.read_csv('data/data_reviews/x_train.csv')['text'].values.tolist()\r\n",
    "# reviews = list()\r\n",
    "\r\n",
    "# pattern = re.compile('[^a-z ]')\r\n",
    "# for review in raw_reviews:\r\n",
    "#     review = review.lower()\r\n",
    "#     review = pattern.sub('', review)\r\n",
    "#     reviews.append(review)\r\n",
    "\r\n",
    "# vectorizer = TfidfVectorizer()\r\n",
    "# X = vectorizer.fit_transform(reviews)\r\n",
    "# y = pd.read_csv('data/data_reviews/y_train.csv').to_numpy().ravel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # n-grams\r\n",
    "# raw_train_reviews = pd.read_csv('data/data_reviews/x_train.csv')['text'].values.tolist()\r\n",
    "# train_reviews = list()\r\n",
    "# raw_test_reviews = pd.read_csv('data/data_reviews/x_test.csv')['text'].values.tolist()\r\n",
    "# test_reviews = list()\r\n",
    "\r\n",
    "# pattern = re.compile('[^a-z ]')\r\n",
    "# for review in raw_train_reviews:\r\n",
    "#     review = review.lower()\r\n",
    "#     review = pattern.sub('', review)\r\n",
    "#     train_reviews.append(review)\r\n",
    "\r\n",
    "# for review in raw_test_reviews:\r\n",
    "#     review = review.lower()\r\n",
    "#     review = pattern.sub('', review)\r\n",
    "#     test_reviews.append(review)\r\n",
    "\r\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,3))\r\n",
    "# fitter = vectorizer.fit(train_reviews)\r\n",
    "# X = fitter.transform(train_reviews)\r\n",
    "# y = pd.read_csv('data/data_reviews/y_train.csv').to_numpy().ravel()\r\n",
    "\r\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,3))\r\n",
    "# X_test = fitter.transform(test_reviews)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# n-grams\r\n",
    "raw_train_reviews = pd.read_csv('data/data_reviews/x_train.csv')['text'].values.tolist()\r\n",
    "train_reviews = list()\r\n",
    "raw_test_reviews = pd.read_csv('data/data_reviews/x_test.csv')['text'].values.tolist()\r\n",
    "test_reviews = list()\r\n",
    "\r\n",
    "pattern = re.compile('[^a-z ]')\r\n",
    "for review in raw_train_reviews:\r\n",
    "    review = review.lower()\r\n",
    "    review = pattern.sub('', review)\r\n",
    "    train_reviews.append(review)\r\n",
    "\r\n",
    "for review in raw_test_reviews:\r\n",
    "    review = review.lower()\r\n",
    "    review = pattern.sub('', review)\r\n",
    "    test_reviews.append(review)\r\n",
    "\r\n",
    "all_reviews = train_reviews + test_reviews\r\n",
    "\r\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\r\n",
    "fitter = vectorizer.fit(all_reviews)\r\n",
    "# all_X = fitter.transform(all_reviews)\r\n",
    "X_train = fitter.transform(train_reviews)\r\n",
    "X_test = fitter.transform(test_reviews)\r\n",
    "\r\n",
    "# print(all_X.shape)\r\n",
    "# print(X_train.shape)\r\n",
    "# print(X_test.shape)\r\n",
    "y_train = list(pd.read_csv('data/data_reviews/y_train.csv')['is_positive_sentiment'])\r\n",
    "y_test = np.array(pd.read_csv('data/data_reviews/y_test.csv')['is_positive_sentiment'])\r\n",
    "# y = y_train + y_test\r\n",
    "\r\n",
    "# final_model = linear_model.LogisticRegression(solver='liblinear', penalty='l1', C=18.4, tol=0.008)\r\n",
    "\r\n",
    "\r\n",
    "# all_indices = list(range(2400))\r\n",
    "# valid_indices = random.sample(all_indices, 360)\r\n",
    "# train_indices = list()\r\n",
    "# for i in all_indices:\r\n",
    "#     if i not in valid_indices:\r\n",
    "#         train_indices.append(i)\r\n",
    "\r\n",
    "# valid_x = list()\r\n",
    "# valid_y = list()\r\n",
    "# r = list()\r\n",
    "# train_x = list()\r\n",
    "# train_y = list()\r\n",
    "# for i in valid_indices:\r\n",
    "#     valid_x.append(X_train[i].toarray())\r\n",
    "#     valid_y.append(y_train[i])\r\n",
    "#     r.append(raw_train_reviews[i])\r\n",
    "# for i in train_indices:\r\n",
    "#     train_x.append(X_train[i].toarray())\r\n",
    "#     train_y.append(y_train[i])\r\n",
    "# train_x = np.array(train_x).reshape(2040, -1)\r\n",
    "# valid_x = np.array(valid_x).reshape(360, -1)\r\n",
    "# print(train_x.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "final_model = linear_model.LogisticRegression(solver='liblinear', penalty='l1', C=18.4, tol=0.008)\r\n",
    "final_model.fit(X_train, y_train)\r\n",
    "train_probas = minmax_scale(final_model.decision_function(X_train).reshape(-1,1))\r\n",
    "# test_probas = minmax_scale(final_model.decision_function(X_test).reshape(-1,1))\r\n",
    "test_probas = final_model.predict_proba(X_test)[:,1]\r\n",
    "print(test_probas)\r\n",
    "print(log_loss(y_test, test_probas))\r\n",
    "# preds = final_model.predict(valid_x)\r\n",
    "# for i in range(len(valid_y)):\r\n",
    "#     if preds[i] != valid_y[i]:\r\n",
    "#         print(valid_y[i], r[i])\r\n",
    "\r\n",
    "# # test_probas = minmax_scale(final_model.decision_function(X_test).reshape(-1,1))\r\n",
    "# # print(test_probas)\r\n",
    "\r\n",
    "# kf = KFold(shuffle=True, n_splits=5)\r\n",
    "\r\n",
    "# for train_index, val_index in kf.split(X_train):\r\n",
    "#     r = list()\r\n",
    "#     x_train, x_val = X_train[train_index], X_train[val_index]\r\n",
    "#     y_train, y_val = y_train[train_index], y_train[val_index]\r\n",
    "#     r.append(raw_train_reviews[val_index])\r\n",
    "#     final_model.fit(x_train, y_train)\r\n",
    "    \r\n",
    "\r\n",
    "#     y_pred = final_model.predict(x_val)\r\n",
    "#     if y_pred[i] != y_val[i]:\r\n",
    "#         print(y_val[i], r[i])\r\n",
    "\r\n",
    "np.savetxt('yproba1_test.txt', test_probas)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9.99475481e-01 4.19447592e-02 8.14477295e-03 4.45804295e-01\n",
      " 1.23038357e-01 4.22172103e-01 1.93729197e-03 9.67064286e-01\n",
      " 9.91832510e-01 9.43922459e-01 8.66917310e-01 3.37643952e-03\n",
      " 2.44601382e-02 9.17405034e-01 9.00710978e-01 3.66463896e-02\n",
      " 2.68171909e-02 5.79932340e-02 9.68462596e-03 9.76383367e-02\n",
      " 9.57538822e-01 3.24809282e-01 3.41777618e-01 2.86526244e-01\n",
      " 3.98973634e-02 2.32164514e-01 1.04760349e-01 4.96542588e-01\n",
      " 9.72775315e-01 2.02099129e-02 9.34368053e-01 1.14027501e-01\n",
      " 1.64645068e-02 7.13353465e-03 4.47572681e-04 9.99346753e-01\n",
      " 2.69400768e-01 9.74313798e-02 3.97056410e-02 9.98336388e-01\n",
      " 6.47165998e-03 8.04099379e-01 4.20643155e-02 8.14674162e-01\n",
      " 3.89633404e-01 3.50674536e-01 9.65079940e-01 2.72659724e-01\n",
      " 6.76419202e-01 4.94219825e-02 6.10363429e-04 9.65780134e-01\n",
      " 9.99960332e-01 3.52972645e-02 6.38245164e-01 5.08255589e-01\n",
      " 9.53605007e-01 2.97913826e-01 7.72207294e-02 9.20870067e-01\n",
      " 8.54808007e-01 9.60663627e-01 5.26458225e-01 9.11102981e-01\n",
      " 9.91740848e-01 1.52121778e-02 1.98309193e-02 4.85230219e-01\n",
      " 9.99237219e-01 9.88645239e-01 6.12185255e-03 1.50343840e-02\n",
      " 8.98744085e-02 4.05160865e-02 9.97221477e-01 5.60011255e-01\n",
      " 5.82657758e-01 3.83808888e-01 5.14095321e-01 8.05645488e-03\n",
      " 6.34695381e-01 3.12533377e-01 4.85413624e-01 4.86480447e-01\n",
      " 8.46474996e-01 2.71319980e-02 1.78419849e-01 9.95368292e-01\n",
      " 3.21253949e-01 6.22583702e-01 4.38336987e-01 9.99011411e-01\n",
      " 2.33726405e-02 1.53992613e-02 9.53623824e-01 9.93060891e-01\n",
      " 3.09424566e-02 9.73654701e-01 1.01401851e-01 2.76671802e-05\n",
      " 5.32713593e-02 9.97628947e-04 4.99831093e-01 9.68826073e-01\n",
      " 9.41508335e-01 4.10591045e-01 8.96066410e-01 3.66463896e-02\n",
      " 6.60076855e-01 9.13891384e-01 9.15687417e-01 6.51458870e-01\n",
      " 5.21289525e-01 9.91180823e-01 9.59579466e-01 7.04603255e-01\n",
      " 9.46818981e-01 9.79188962e-01 9.98499212e-01 4.17430185e-01\n",
      " 9.74785422e-01 9.62027530e-01 4.34597684e-02 5.49545301e-02\n",
      " 1.55272978e-03 4.86599627e-01 2.03468448e-03 1.40259507e-02\n",
      " 1.27101411e-02 6.06778836e-01 4.61279878e-01 9.54768348e-01\n",
      " 2.07508695e-01 8.06111797e-02 5.45823392e-01 8.09410265e-01\n",
      " 6.10580110e-01 4.98997835e-01 2.45848407e-01 9.96826359e-01\n",
      " 6.70101423e-02 4.98997835e-01 1.19741282e-01 1.23884976e-02\n",
      " 4.73057620e-01 7.52496914e-02 9.99998717e-01 6.21053642e-05\n",
      " 6.35022135e-02 2.40114015e-02 4.81413067e-03 2.00457864e-03\n",
      " 9.81786151e-01 1.06789991e-01 4.71287557e-02 8.78750487e-03\n",
      " 8.78563247e-01 6.35053573e-01 9.95914395e-01 2.80333267e-01\n",
      " 1.87368883e-02 1.68313300e-01 8.88999660e-01 6.74444358e-02\n",
      " 4.55249769e-01 6.97096670e-01 1.95307678e-02 5.94304080e-01\n",
      " 1.31041379e-01 9.00710978e-01 4.86597180e-02 2.73414767e-01\n",
      " 1.04714484e-03 4.03988617e-01 9.98372795e-01 9.99959601e-01\n",
      " 9.38869061e-01 9.20360996e-01 7.36165751e-01 1.25600916e-02\n",
      " 1.39692952e-02 9.96664888e-01 2.25171961e-02 1.31330144e-01\n",
      " 9.70108251e-01 1.45149934e-01 9.99414526e-01 8.05717293e-01\n",
      " 9.66426901e-01 8.59518463e-01 1.27284324e-01 8.01540499e-01\n",
      " 1.48202605e-05 9.90502899e-01 7.45229214e-01 2.98759095e-02\n",
      " 2.24891642e-01 1.53811059e-02 1.50786585e-02 2.22358939e-02\n",
      " 4.57260713e-01 9.49058048e-01 1.86511767e-02 5.89763068e-03\n",
      " 7.82158419e-04 9.60250037e-01 8.50477011e-01 4.43341343e-01\n",
      " 3.79983278e-01 1.08040117e-01 9.24908804e-01 1.47271455e-01\n",
      " 2.12921256e-02 9.99815216e-01 3.71398248e-02 3.91817505e-01\n",
      " 3.17474702e-02 9.38510472e-01 3.44151319e-01 9.99890283e-01\n",
      " 8.22422481e-02 9.19410769e-01 5.11000301e-02 7.65937960e-01\n",
      " 7.97040141e-01 9.90819855e-01 4.51085964e-02 8.43092255e-01\n",
      " 2.97267427e-02 2.57649013e-04 2.14398460e-01 1.79753761e-01\n",
      " 2.40350892e-01 9.93848670e-01 8.27535779e-01 5.99704344e-01\n",
      " 9.97449252e-01 6.43346792e-03 3.87246795e-01 9.99511212e-01\n",
      " 9.69822536e-01 9.47773671e-01 9.67028776e-01 8.29566672e-01\n",
      " 1.00645029e-03 1.06580573e-01 2.09861597e-04 1.11093290e-01\n",
      " 5.67995976e-02 9.91218845e-01 9.90971051e-01 3.68922144e-04\n",
      " 6.68321279e-01 9.40251462e-01 9.97862628e-01 5.09102940e-01\n",
      " 3.66404192e-01 9.94145171e-01 9.56935875e-01 9.73772189e-02\n",
      " 1.17954783e-04 9.09519461e-01 9.74164941e-01 9.67698186e-01\n",
      " 4.18931058e-01 9.94106430e-01 1.62426870e-01 2.61277865e-01\n",
      " 3.33122194e-01 9.52236720e-01 1.41338849e-07 1.30726230e-02\n",
      " 8.07842339e-01 9.94140001e-01 3.62842394e-01 4.85704149e-03\n",
      " 8.79372446e-01 4.60790760e-02 1.93579994e-02 9.83260746e-01\n",
      " 8.02989685e-03 7.14795770e-03 4.56204094e-02 7.20984577e-01\n",
      " 3.58404655e-01 3.85626629e-01 3.91558455e-02 7.31588049e-01\n",
      " 8.73168175e-03 6.91169016e-01 4.46702462e-03 1.60685300e-03\n",
      " 8.39048564e-01 9.57615496e-01 8.10034501e-02 4.26335073e-01\n",
      " 8.56420084e-01 9.31372420e-01 9.86953611e-01 6.99525605e-01\n",
      " 8.50456119e-01 8.04773800e-01 7.09416317e-01 6.84695685e-01\n",
      " 1.14392170e-02 9.83531753e-01 9.13442560e-03 8.04865226e-03\n",
      " 9.96500377e-01 8.15916364e-03 2.63055770e-03 2.08707485e-01\n",
      " 9.67315271e-01 1.69872861e-01 3.39674747e-03 9.89397322e-01\n",
      " 6.80142823e-02 9.50376202e-01 9.73437792e-01 6.72078543e-01\n",
      " 1.14425241e-01 9.79694093e-01 9.56935875e-01 2.08091075e-02\n",
      " 6.67754416e-03 2.84275376e-01 5.62897761e-01 9.91106136e-01\n",
      " 9.98282291e-01 9.90136009e-01 3.29905405e-01 4.21095844e-01\n",
      " 9.92681338e-01 9.83185808e-01 9.57750106e-01 8.34786897e-01\n",
      " 9.02529899e-01 9.68140732e-01 9.96240569e-01 5.21443345e-01\n",
      " 2.32371964e-02 6.83942640e-02 6.22535801e-01 2.79832265e-02\n",
      " 9.39078402e-01 9.99456768e-01 2.94778991e-01 9.76078495e-01\n",
      " 9.20470452e-02 3.30031163e-02 1.41251129e-02 2.59692702e-01\n",
      " 3.33416526e-03 5.29896391e-01 2.87202057e-01 8.92549701e-02\n",
      " 9.01348632e-01 2.08358284e-02 3.52259188e-01 9.81717568e-01\n",
      " 1.33476324e-02 1.90565233e-02 9.16566607e-01 1.39378679e-01\n",
      " 2.78751773e-01 6.38437403e-02 8.68866300e-01 9.17992192e-02\n",
      " 9.96266710e-01 5.67256905e-01 5.80520886e-02 9.14752639e-02\n",
      " 9.99346192e-01 1.25786534e-02 4.45568461e-03 7.86534607e-01\n",
      " 8.77105964e-01 3.79959432e-02 9.93318288e-01 7.52804157e-01\n",
      " 9.98982852e-01 4.57256550e-01 2.97392052e-02 2.32443950e-03\n",
      " 4.36237169e-01 3.54198363e-01 8.86730071e-01 9.43169398e-01\n",
      " 1.14561158e-02 2.00588802e-02 6.38281717e-01 9.00475098e-03\n",
      " 8.26893814e-01 1.42906564e-01 1.63598557e-01 5.93307136e-03\n",
      " 9.99745079e-01 9.64388254e-01 4.27819518e-02 9.62556323e-01\n",
      " 6.89838916e-02 1.06521809e-02 8.31947716e-01 1.45657836e-02\n",
      " 4.76161656e-02 9.96146322e-01 9.56273285e-01 9.99716799e-01\n",
      " 9.21115686e-01 3.10549940e-01 3.62965834e-01 8.27434127e-01\n",
      " 9.93369153e-01 7.57507478e-03 2.43163615e-02 9.51777132e-01\n",
      " 2.12399609e-02 2.26337382e-01 1.28665862e-03 4.33784989e-01\n",
      " 7.36203452e-01 1.85635919e-01 6.08026721e-01 4.15820778e-01\n",
      " 2.35792514e-01 9.97560826e-01 9.99318491e-01 1.65713292e-01\n",
      " 1.41568823e-01 4.05398765e-01 7.21769299e-02 4.28502070e-03\n",
      " 6.90949932e-03 5.60131534e-01 6.86274679e-03 9.99974019e-01\n",
      " 5.74285295e-01 1.12433566e-02 2.07231972e-03 8.75443420e-01\n",
      " 1.40637794e-01 9.78736683e-01 2.18596592e-01 5.84439109e-01\n",
      " 1.51111604e-01 9.41550808e-01 1.67976077e-03 7.14067294e-02\n",
      " 8.35529713e-04 9.69166337e-01 9.97554083e-01 1.17993351e-01\n",
      " 3.01172613e-01 1.22031348e-02 6.98122983e-01 4.67140432e-01\n",
      " 4.90672177e-01 4.68081778e-01 6.46657975e-01 4.17519881e-01\n",
      " 3.45469111e-03 1.03538622e-01 6.36227457e-03 6.92012101e-01\n",
      " 5.91115447e-01 2.83834006e-01 1.91734997e-01 6.87275073e-01\n",
      " 9.99528066e-01 9.97509801e-01 4.01337350e-01 6.31612367e-03\n",
      " 8.92335028e-01 9.28394287e-01 3.86617760e-02 9.88669594e-01\n",
      " 3.38360354e-01 8.58254236e-01 1.45786217e-02 3.88688706e-03\n",
      " 9.48652301e-01 4.99831093e-01 6.65168226e-01 2.19701340e-01\n",
      " 9.96895017e-01 1.78153844e-02 3.61140042e-01 3.86950326e-01\n",
      " 9.99234852e-01 9.99971851e-01 7.54217955e-01 1.65490043e-01\n",
      " 5.67025963e-01 9.86771428e-01 1.55636125e-02 9.95191224e-01\n",
      " 4.35764296e-03 2.30251081e-03 2.97380480e-01 2.01347464e-01\n",
      " 2.00581016e-01 8.14477295e-03 9.05165425e-01 9.55157339e-01\n",
      " 2.00993042e-01 8.42599970e-02 2.17476357e-01 4.62241925e-04\n",
      " 2.00458307e-01 6.71525145e-01 2.54062352e-01 9.44543379e-01\n",
      " 2.64759481e-01 4.82342691e-01 9.96532321e-01 1.03389863e-01\n",
      " 6.21828855e-01 9.57648672e-01 5.40962540e-01 9.08883928e-01\n",
      " 9.58692159e-01 3.47587467e-01 1.26655388e-01 5.69810356e-01\n",
      " 2.59463907e-01 8.05500836e-02 5.93692203e-01 4.07925339e-02\n",
      " 8.81518704e-01 8.22851826e-03 2.71389424e-02 8.56588433e-01\n",
      " 9.97132766e-01 9.79055986e-01 2.04376708e-01 1.60037430e-01\n",
      " 1.57587312e-02 9.63951665e-02 4.52842856e-01 1.05252503e-01\n",
      " 3.43998525e-03 9.99512221e-01 9.01859157e-01 2.09911157e-01\n",
      " 9.46624929e-03 1.31680100e-01 9.91456363e-01 7.97361551e-02\n",
      " 3.85841227e-01 3.78365855e-01 1.98184853e-01 9.54487141e-01\n",
      " 9.41214893e-01 1.29039805e-02 4.11204823e-01 9.85960317e-01\n",
      " 2.47939001e-01 6.15491601e-02 4.76149276e-10 1.65488064e-01\n",
      " 1.45299836e-02 8.71447207e-01 4.35792191e-02 1.22629415e-04\n",
      " 1.75479388e-01 9.89982301e-02 3.74668586e-01 1.56102378e-04\n",
      " 1.83647631e-01 2.92410887e-01 8.92172838e-01 3.51261839e-01\n",
      " 9.91045574e-01 6.71182106e-01 9.97829772e-01 2.45765106e-01\n",
      " 2.70293355e-02 9.12041309e-01 1.93268726e-01 1.06271879e-01\n",
      " 5.24808567e-01 9.86079782e-01 9.91922100e-01 4.57467408e-01\n",
      " 9.99778909e-01 1.66994641e-01 9.56935875e-01 6.40997587e-01\n",
      " 8.20504716e-01 6.33964925e-02 7.50658172e-01 4.05216610e-01\n",
      " 4.91483016e-01 9.68344462e-01 2.26962824e-01 9.81892226e-01\n",
      " 9.73779383e-01 9.38681684e-01 7.46744615e-01 4.05980889e-01]\n",
      "0.4440596491959491\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BOW w "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Default"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(shuffle=True)\r\n",
    "log_model = linear_model.LogisticRegression()\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    log_model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "    \r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LBFGS L2\r\n",
    "best C: 8.68511373751352"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best C\r\n",
    "train_scores = list()\r\n",
    "val_scores = list()\r\n",
    "\r\n",
    "best_c = 10**-2\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "for c in np.logspace(-2, 2, 50):\r\n",
    "    log_model = linear_model.LogisticRegression(solver='lbfgs', penalty='l2', max_iter=500, C=c)\r\n",
    "    \r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "    \r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        log_model.fit(x_train, y_train)\r\n",
    "                \r\n",
    "        k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_c = c\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "\r\n",
    "    print('C: {:2f}   score: {:5f}'.format(c, np.mean(k_val_scores)))\r\n",
    "\r\n",
    "print('best C:', best_c)\r\n",
    "\r\n",
    "# plot accuracy\r\n",
    "plt.title('Model Accuracy vs Inverse Regularization Penalty, C')\r\n",
    "plt.xlabel('inverse regularization penalty, C')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-2, 2, 50), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-2, 2, 50), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best tol\r\n",
    "train_scores = list()\r\n",
    "val_scores = list()\r\n",
    "\r\n",
    "best_tol = 10**-8\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "for t in np.logspace(-8, 4, 50):\r\n",
    "    log_model = linear_model.LogisticRegression(solver='lbfgs', penalty='l2', max_iter=500, C=best_c)\r\n",
    "    \r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "    \r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        log_model.fit(x_train, y_train)\r\n",
    "        \r\n",
    "        k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_tol = t\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "\r\n",
    "    print('tol: {:8f}   score: {:5f}'.format(t, np.mean(k_val_scores)))\r\n",
    "\r\n",
    "print('best tol:', best_tol)\r\n",
    "\r\n",
    "# plot tolerance\r\n",
    "plt.title('Model Accuracy vs Tolerance')\r\n",
    "plt.xlabel('tolerance')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-8, 4, 50), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-8, 4, 50), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# best model details\r\n",
    "\r\n",
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "log_model = linear_model.LogisticRegression(solver='lbfgs', penalty='l2', max_iter=500, C=best_c)\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    log_model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LBFGS none"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(shuffle=True)\r\n",
    "log_model = linear_model.LogisticRegression(solver='lbfgs', penalty='none', max_iter=500)\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    log_model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "    \r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### liblinear L2\r\n",
    "best C: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best C\r\n",
    "train_scores = list()\r\n",
    "val_scores = list()\r\n",
    "\r\n",
    "best_c = 10**-2\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "for c in np.logspace(-2, 2, 50):\r\n",
    "    log_model = linear_model.LogisticRegression(solver='liblinear', penalty='l2', max_iter=500, C=c)\r\n",
    "    \r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "    \r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        log_model.fit(x_train, y_train)\r\n",
    "                \r\n",
    "        k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_c = c\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "\r\n",
    "    print('C: {:2f}   score: {:5f}'.format(c, np.mean(k_val_scores)))\r\n",
    "\r\n",
    "print('best C:', best_c)\r\n",
    "\r\n",
    "# plot accuracy\r\n",
    "plt.title('Model Accuracy vs Inverse Regularization Penalty, C')\r\n",
    "plt.xlabel('inverse regularization penalty, C')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-2, 2, 50), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-2, 2, 50), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best tol\r\n",
    "train_scores = list()\r\n",
    "val_scores = list()\r\n",
    "\r\n",
    "best_tol = 10**-8\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "for t in np.logspace(-8, 4, 50):\r\n",
    "    log_model = linear_model.LogisticRegression(solver='liblinear', penalty='l2', max_iter=500, C=best_c)\r\n",
    "    \r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "    \r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        log_model.fit(x_train, y_train)\r\n",
    "        \r\n",
    "        k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_tol = t\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "\r\n",
    "    print('tol: {:8f}   score: {:5f}'.format(t, np.mean(k_val_scores)))\r\n",
    "\r\n",
    "print('best tol:', best_tol)\r\n",
    "\r\n",
    "# plot tolerance\r\n",
    "plt.title('Model Accuracy vs Tolerance')\r\n",
    "plt.xlabel('tolerance')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-8, 4, 50), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-8, 4, 50), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# best model details\r\n",
    "\r\n",
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "log_model = linear_model.LogisticRegression(solver='liblinear', penalty='l2', max_iter=500, C=15, tol=1.6)\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    log_model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### liblinear L1\r\n",
    "best C: 8.68511373751352"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best C\r\n",
    "train_scores = list()\r\n",
    "val_scores = list()\r\n",
    "\r\n",
    "best_c = 10**-2\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "for c in np.logspace(-2, 2, 50):\r\n",
    "    log_model = linear_model.LogisticRegression(solver='liblinear', penalty='l1', max_iter=500, C=c)\r\n",
    "    \r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "    \r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        log_model.fit(x_train, y_train)\r\n",
    "                \r\n",
    "        k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_c = c\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "\r\n",
    "    print('C: {:2f}   score: {:5f}'.format(c, np.mean(k_val_scores)))\r\n",
    "\r\n",
    "print('best C:', best_c)\r\n",
    "\r\n",
    "# plot accuracy\r\n",
    "plt.title('Model Accuracy vs Inverse Regularization Penalty, C')\r\n",
    "plt.xlabel('inverse regularization penalty, C')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-2, 2, 50), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-2, 2, 50), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best tol\r\n",
    "train_scores = list()\r\n",
    "val_scores = list()\r\n",
    "\r\n",
    "best_tol = 10**-8\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "for t in np.logspace(-8, 4, 50):\r\n",
    "    log_model = linear_model.LogisticRegression(solver='liblinear', penalty='l1', max_iter=500, C=best_c, tol=t)\r\n",
    "    \r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "    \r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        log_model.fit(x_train, y_train)\r\n",
    "        \r\n",
    "        k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_tol = t\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "\r\n",
    "    print('tol: {:8f}   score: {:5f}'.format(t, np.mean(k_val_scores)))\r\n",
    "\r\n",
    "print('best tol:', best_tol)\r\n",
    "\r\n",
    "# plot tolerance\r\n",
    "plt.title('Model Accuracy vs Tolerance')\r\n",
    "plt.xlabel('tolerance')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-8, 4, 50), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-8, 4, 50), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# best model details\r\n",
    "\r\n",
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "log_model = linear_model.LogisticRegression(solver='liblinear', penalty='l1', max_iter=500, C=best_c, tol=best_tol)\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    log_model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(log_model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(log_model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "parameters = {\r\n",
    "    'solver': ['adam', 'lbfgs'],\r\n",
    "    'activation': ['logistic', 'relu'],\r\n",
    "    'alpha': list(np.logspace(-3, 2, 25)),\r\n",
    "    'tol': [10**i for i in range(-8, 3, 1)]\r\n",
    "}\r\n",
    "\r\n",
    "mlp = RandomizedSearchCV(MLPClassifier(), parameters, n_iter=16)\r\n",
    "mlp.fit(X,y)\r\n",
    "\r\n",
    "pd.DataFrame(mlp.cv_results_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Default logistic\r\n",
    "pretty trash -- ~15% worse than ReLU or ID"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "model = MLPClassifier(activation='logistic')\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Default ReLU"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "model = MLPClassifier(activation='relu')\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Default identity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "model = MLPClassifier(activation='identity')\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "LBFGS Logistic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "model = MLPClassifier(solver='lbfgs', activation='logistic')\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LBFGS ReLU"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "model = MLPClassifier(solver='lbfgs', activation='relu')\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LBFGS identity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kf = KFold(shuffle=True, n_splits=10)\r\n",
    "model = MLPClassifier(solver='lbfgs', activation='identity')\r\n",
    "\r\n",
    "k_train_scores = list()\r\n",
    "k_val_scores = list()\r\n",
    "\r\n",
    "for train_index, val_index in kf.split(X):\r\n",
    "    x_train, x_val = X[train_index], X[val_index]\r\n",
    "    y_train, y_val = y[train_index], y[val_index]\r\n",
    "    model.fit(x_train, y_train)\r\n",
    "\r\n",
    "    k_train_scores.append(model.score(x_train, y_train))\r\n",
    "    k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   TRAIN -- score: {:5f}'.format(k_train_scores[-1]), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(k_val_scores[-1]))\r\n",
    "\r\n",
    "print('TRAIN -- score: {:5f}'.format(np.mean(k_train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "print('std:', np.std(k_val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best alpha\r\n",
    "train_scores = list()\r\n",
    "val_scores = list()\r\n",
    "\r\n",
    "best_alpha = 10**-8\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "for a in np.logspace(-8, 2, 20):\r\n",
    "    model = MLPClassifier(solver='lbfgs', activation='relu', alpha=a)\r\n",
    "    \r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "    \r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        model.fit(x_train, y_train)\r\n",
    "                \r\n",
    "        k_train_scores.append(model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_alpha = a\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "\r\n",
    "    print('alpha: {:2f}   score: {:5f}'.format(alpha, np.mean(k_val_scores)))\r\n",
    "\r\n",
    "print('best alpha:', best_alpha)\r\n",
    "\r\n",
    "# plot accuracy\r\n",
    "plt.title('Model Accuracy vs Regularization Penalty, alpha')\r\n",
    "plt.xlabel('regularization penalty alpha')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-8, 2, 20), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-8, 2, 20), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best tol\r\n",
    "train_scores = list()\r\n",
    "val_scores = list()\r\n",
    "\r\n",
    "best_tol = 10**-8\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "for t in np.logspace(-8, 4, 20):\r\n",
    "    model = MLPClassifier(solver='lbfgs', activation='relu', alpha=best_alpha, tol=t)\r\n",
    "    \r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "    \r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        model.fit(x_train, y_train)\r\n",
    "        \r\n",
    "        k_train_scores.append(model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_tol = t\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "\r\n",
    "    print('tol: {:8f}   score: {:5f}'.format(t, np.mean(k_val_scores)))\r\n",
    "\r\n",
    "print('best tol:', best_tol)\r\n",
    "\r\n",
    "# plot tolerance\r\n",
    "plt.title('Model Accuracy vs Tolerance')\r\n",
    "plt.xlabel('tolerance')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-8, 4, 50), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-8, 4, 50), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot tolerance\r\n",
    "plt.title('Model Accuracy vs Tolerance')\r\n",
    "plt.xlabel('tolerance')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.plot(np.logspace(-8, 4, 20), train_scores, c='r', label='train')\r\n",
    "plt.plot(np.logspace(-8, 4, 20), val_scores, label='validation')\r\n",
    "plt.xscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ADAM ReLU"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best alpha\r\n",
    "val_scores = list()\r\n",
    "train_scores = list()\r\n",
    "\r\n",
    "best_alpha = 10**-3\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "\r\n",
    "for a in np.logspace(-3, 3, 15):\r\n",
    "    model = MLPClassifier(solver='adam', activation='relu', alpha=a)\r\n",
    "\r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "\r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        model.fit(x_train, y_train)\r\n",
    "\r\n",
    "        k_train_scores.append(model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   alpha: {:4f}   TRAIN -- score: {:5f}'.format(a, np.mean(k_train_scores)), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "    print('   std:', np.std(k_val_scores))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_alpha = a\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "    \r\n",
    "print('best alpha: {:4f}   TRAIN -- score: {:5f}'.format(best_alpha, np.mean(train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(val_scores)))\r\n",
    "print('std:', np.std(val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find best tol\r\n",
    "val_scores = list()\r\n",
    "train_scores = list()\r\n",
    "\r\n",
    "best_tol = 10**-8\r\n",
    "best_score = 0\r\n",
    "\r\n",
    "kf = KFold(shuffle=True)\r\n",
    "\r\n",
    "for t in np.logspace(-12, 4, 15):\r\n",
    "    model = MLPClassifier(solver='adam', activation='relu', alpha=best_alpha, tol=t)\r\n",
    "\r\n",
    "    k_train_scores = list()\r\n",
    "    k_val_scores = list()\r\n",
    "\r\n",
    "    for train_index, val_index in kf.split(X):\r\n",
    "        x_train, x_val = X[train_index], X[val_index]\r\n",
    "        y_train, y_val = y[train_index], y[val_index]\r\n",
    "        model.fit(x_train, y_train)\r\n",
    "\r\n",
    "        k_train_scores.append(model.score(x_train, y_train))\r\n",
    "        k_val_scores.append(model.score(x_val, y_val))\r\n",
    "\r\n",
    "    print('   tol: {:4f}   TRAIN -- score: {:5f}'.format(t, np.mean(k_train_scores)), end='')\r\n",
    "    print('      VALID -- score: {:5f}'.format(np.mean(k_val_scores)))\r\n",
    "    print('   std:', np.std(k_val_scores))\r\n",
    "\r\n",
    "    if np.mean(k_val_scores) > best_score:\r\n",
    "        best_tol = t\r\n",
    "        best_score = np.mean(k_val_scores)\r\n",
    "\r\n",
    "    train_scores.append(np.mean(k_train_scores))\r\n",
    "    val_scores.append(np.mean(k_val_scores))\r\n",
    "    \r\n",
    "print('best tol: {:4f}   TRAIN -- score: {:5f}'.format(best_tol, np.mean(train_scores)), end='')\r\n",
    "print('      VALID -- score: {:5f}'.format(np.mean(val_scores)))\r\n",
    "print('std:', np.std(val_scores))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # find best tolerance\r\n",
    "# train_scores = list()\r\n",
    "# train_aucs = list()\r\n",
    "# train_losses = list()\r\n",
    "\r\n",
    "# val_scores = list()\r\n",
    "# val_aucs = list()\r\n",
    "# val_losses = list()\r\n",
    "\r\n",
    "# best_tol = 10**-8\r\n",
    "# best_loss = 1000\r\n",
    "\r\n",
    "# tols = list()\r\n",
    "# for i in range(-12, 4, 1):\r\n",
    "#     tols.append(10**i)\r\n",
    "\r\n",
    "\r\n",
    "# kf = KFold(shuffle=True)\r\n",
    "# for t in tols:\r\n",
    "#     model = MLPClassifier(activation='relu', solver='adam', alpha=best_alpha, tol=t)\r\n",
    "    \r\n",
    "#     k_train_scores = list()\r\n",
    "#     k_train_aucs = list()\r\n",
    "#     k_train_losses = list()\r\n",
    "    \r\n",
    "#     k_val_scores = list()\r\n",
    "#     k_val_aucs = list()\r\n",
    "#     k_val_losses = list()\r\n",
    "    \r\n",
    "#     for train_index, val_index in kf.split(X):\r\n",
    "#         x_train, x_val = X[train_index], X[val_index]\r\n",
    "#         y_train, y_val = y[train_index], y[val_index]\r\n",
    "#         model.fit(x_train, y_train)\r\n",
    "        \r\n",
    "#         train_probas = model.predict_proba(x_train)[:,1]\r\n",
    "#         val_probas = model.predict_proba(x_val)[:,1]\r\n",
    "                \r\n",
    "#         k_train_scores.append(model.score(x_train, y_train))\r\n",
    "#         k_train_aucs.append(roc_auc_score(y_train, train_probas))\r\n",
    "#         k_train_losses.append(log_loss(y_train, train_probas))\r\n",
    "\r\n",
    "#         k_val_scores.append(model.score(x_val, y_val))\r\n",
    "#         k_val_aucs.append(roc_auc_score(y_val, val_probas))\r\n",
    "#         k_val_losses.append(log_loss(y_val, val_probas))\r\n",
    "\r\n",
    "#     if np.mean(k_val_losses) < best_loss:\r\n",
    "#         best_tol = t\r\n",
    "#         best_loss = np.mean(k_val_losses)\r\n",
    "\r\n",
    "#     train_scores.append(np.mean(k_train_scores))\r\n",
    "#     train_aucs.append(np.mean(k_train_aucs))\r\n",
    "#     train_losses.append(np.mean(k_train_losses))\r\n",
    "\r\n",
    "#     val_scores.append(np.mean(k_val_scores))\r\n",
    "#     val_aucs.append(np.mean(k_val_aucs))\r\n",
    "#     val_losses.append(np.mean(k_val_losses))\r\n",
    "\r\n",
    "#     print('tol: {}   score: {:5f}   auc: {:5f}   loss: {:5f}'.format(\r\n",
    "#         t,\r\n",
    "#         np.mean(k_val_scores), \r\n",
    "#         np.mean(k_val_aucs),\r\n",
    "#         np.mean(k_val_losses)))\r\n",
    "\r\n",
    "# print('best tol:', best_tol)\r\n",
    "\r\n",
    "# # plot accuracy vs layer size\r\n",
    "# plt.title('Model Accuracy vs Tolerance')\r\n",
    "# plt.xlabel('tolerance (1e-tol)')\r\n",
    "# plt.ylabel('accuracy')\r\n",
    "# plt.plot(tols, train_scores, c='r', label='train')\r\n",
    "# plt.plot(tols, val_scores, label='validation')\r\n",
    "# plt.xscale('log')\r\n",
    "# plt.legend()\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # get details of best model\r\n",
    "# model = MLPClassifier(activation='relu', solver='adam', alpha=best_alpha, tol=best_tol)\r\n",
    "    \r\n",
    "# k_train_scores = list()\r\n",
    "# k_train_aucs = list()\r\n",
    "# k_train_losses = list()\r\n",
    "\r\n",
    "# k_val_scores = list()\r\n",
    "# k_val_aucs = list()\r\n",
    "# k_val_losses = list()\r\n",
    "\r\n",
    "# for train_index, val_index in kf.split(X):\r\n",
    "#     x_train, x_val = X[train_index], X[val_index]\r\n",
    "#     y_train, y_val = y[train_index], y[val_index]\r\n",
    "#     model.fit(x_train, y_train)\r\n",
    "    \r\n",
    "#     train_probas = model.predict_proba(x_train)[:,1]\r\n",
    "#     val_probas = model.predict_proba(x_val)[:,1]\r\n",
    "            \r\n",
    "#     k_train_scores.append(model.score(x_train, y_train))\r\n",
    "#     k_train_aucs.append(roc_auc_score(y_train, train_probas))\r\n",
    "#     k_train_losses.append(log_loss(y_train, train_probas))\r\n",
    "\r\n",
    "#     k_val_scores.append(model.score(x_val, y_val))\r\n",
    "#     k_val_aucs.append(roc_auc_score(y_val, val_probas))\r\n",
    "#     k_val_losses.append(log_loss(y_val, val_probas))\r\n",
    "\r\n",
    "# print('TRAIN -- auc: {:5f}   loss: {:5f}   score: {:5f}'.format(\r\n",
    "#     np.mean(k_train_aucs),\r\n",
    "#     np.mean(k_train_losses),\r\n",
    "#     np.mean(k_train_scores)))\r\n",
    "\r\n",
    "# print('VALID -- auc: {:5f}   loss: {:5f}   score: {:5f}'.format(\r\n",
    "#     np.mean(k_val_aucs),\r\n",
    "#     np.mean(k_val_losses),\r\n",
    "#     np.mean(k_val_scores)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid search other models "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# parameters = {\r\n",
    "#     'solver': ['lbfgs', 'adam'],\r\n",
    "#     'alpha': list(np.logspace(-3, 3, 20)),\r\n",
    "#     'activation': ['identity', 'relu'],\r\n",
    "#     'tol': list(range(-8, 1, 1))\r\n",
    "# }\r\n",
    "\r\n",
    "# mlp = GridSearchCV(MLPClassifier(), parameters)\r\n",
    "# mlp.fit(X, y)\r\n",
    "\r\n",
    "# pd.DataFrame(mlp.cv_results_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Classifier "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('ml_env': conda)"
  },
  "interpreter": {
   "hash": "5488065bb2d6ca6a9de5ec6734160292494259bd2c5abc9e8432ae79ff9e5079"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}